{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "HTieKNLbywBG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Configuration ----------------------\n",
        "CSV_PATH = '/content/RS-A4_SEER Breast Cancer Dataset .csv' # change if necessary\n",
        "TARGET_COL = 'Status' # column to predict (alive / dead)\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "MODEL_OUTPUT = 'bc_prognosis_model.joblib'\n",
        "PIPE_OUTPUT = 'bc_preproc_pipe.joblib'\n",
        "PROB_THRESHOLD = 0.5 # threshold for \"high risk\""
      ],
      "metadata": {
        "id": "63f-_BoQ_iJR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  df = pd.read_csv(path)\n",
        "  print('Loaded:', df.shape)\n",
        "  return df"
      ],
      "metadata": {
        "id": "P4eoy8Mg_iSO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_target(df, target_col):\n",
        "    # Convert textual status to numeric 1=alive, 0=dead (or the other way around depending on your preference)\n",
        "    # We'll convert to 1 = alive (good), 0 = dead (bad). If user already has 0/1, this will be left as is.\n",
        "    if df[target_col].dtype == object:\n",
        "        mapping = {k.lower(): v for k, v in zip(['alive', 'dead'], [1, 0])}\n",
        "        # attempt mapping robustly\n",
        "        df[target_col] = df[target_col].astype(str).str.strip().str.lower().map({'alive':1, 'dead':0})\n",
        "        # if mapping produced NaNs but values are like '0'/'1'\n",
        "        if df[target_col].isna().any():\n",
        "            try:\n",
        "                df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
        "            except Exception:\n",
        "                pass\n",
        "    return df"
      ],
      "metadata": {
        "id": "CmR70FX9_iZx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Main pipeline builder ----------------------\n",
        "\n",
        "def build_and_train(df, target_col=TARGET_COL):\n",
        "    df = df.copy()\n",
        "    df = standardize_target(df, target_col)\n",
        "\n",
        "    # Drop rows where target is still NaN\n",
        "    df = df.dropna(subset=[target_col])\n",
        "\n",
        "    # Identify feature columns\n",
        "    feature_cols = [c for c in df.columns if c != target_col]\n",
        "\n",
        "    # Simple heuristic: numeric vs categorical\n",
        "    numeric_cols = df[feature_cols].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_cols = [c for c in feature_cols if c not in numeric_cols]\n",
        "\n",
        "    # Build preprocessing\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "\n",
        "    pipe = Pipeline(steps=[('preproc', preprocessor), ('clf', clf)])\n",
        "\n",
        "    # train-test split\n",
        "    X = df[feature_cols]\n",
        "    y = df[target_col].astype(int)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE,\n",
        "                                                        stratify=y, random_state=RANDOM_STATE)\n",
        "\n",
        "    # Optional: quick grid search for n_estimators/depth (small grid)\n",
        "    # grid = {'clf__n_estimators':[100,200], 'clf__max_depth':[None,10,20]}\n",
        "    # search = GridSearchCV(pipe, grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "    # search.fit(X_train, y_train)\n",
        "    # model = search.best_estimator_\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    y_proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe, 'predict_proba') else None\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy on test set: {:.2f}%'.format(acc * 100))\n",
        "    print('\\nClassification Report:\\n', classification_report(y_test, y_pred, digits=4))\n",
        "    if y_proba is not None:\n",
        "        try:\n",
        "            auc = roc_auc_score(y_test, y_proba)\n",
        "            print('ROC AUC: {:.4f}'.format(auc))\n",
        "        except Exception:\n",
        "            pass\n",
        "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Save pipeline\n",
        "    joblib.dump(pipe, PIPE_OUTPUT)\n",
        "    print('Saved preprocessing + model pipeline to', PIPE_OUTPUT)\n",
        "\n",
        "    return pipe, numeric_cols, categorical_cols"
      ],
      "metadata": {
        "id": "iG4o4pGY_ig1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Recommendation function ----------------------\n",
        "\n",
        "def prognosis_recommendation(pipe, patient_row, numeric_cols, categorical_cols, prob_threshold=PROB_THRESHOLD):\n",
        "    \"\"\"\n",
        "    patient_row: pd.Series or 1D-array corresponding to feature columns (order: numeric_cols + categorical_cols)\n",
        "    Returns: dict with prediction, probability, risk_label, top_influential_features, recommendation_text\n",
        "    \"\"\"\n",
        "    # Build a DataFrame from patient_row\n",
        "    if isinstance(patient_row, (list, np.ndarray)):\n",
        "        # user provided numpy array; we need column names\n",
        "        cols = numeric_cols + categorical_cols\n",
        "        x = pd.DataFrame([patient_row], columns=cols)\n",
        "    elif isinstance(patient_row, pd.Series):\n",
        "        x = pd.DataFrame([patient_row.values], columns=patient_row.index)\n",
        "    elif isinstance(patient_row, pd.DataFrame):\n",
        "        x = patient_row\n",
        "    else:\n",
        "        raise ValueError('patient_row must be array-like, Series or DataFrame')\n",
        "\n",
        "    # Predict\n",
        "    proba = pipe.predict_proba(x)[:, 1][0] if hasattr(pipe, 'predict_proba') else None\n",
        "    pred = pipe.predict(x)[0]\n",
        "\n",
        "    # Decide risk: here 0=dead(bad),1=alive(good). We want to say high risk if probability of 'alive' < threshold.\n",
        "    # But because classes might be reversed, we'll check mapping via label ordering\n",
        "    classes = pipe.named_steps['clf'].classes_\n",
        "    # index of class 'alive' (1) if present\n",
        "    if 1 in classes:\n",
        "        alive_index = list(classes).index(1)\n",
        "        prob_alive = pipe.predict_proba(x)[:, alive_index][0]\n",
        "    else:\n",
        "        # fallback: use positive class probability as returned\n",
        "        prob_alive = proba\n",
        "\n",
        "    risk_label = 'High risk' if prob_alive < prob_threshold else 'Low/Moderate risk'\n",
        "\n",
        "    # Simple feature importance extraction -- map back to original feature names\n",
        "    # Works only for tree-based models\n",
        "    feat_info = []\n",
        "    try:\n",
        "        import numpy as _np\n",
        "        clf = pipe.named_steps['clf']\n",
        "        # get feature names after preprocessor\n",
        "        ohe = pipe.named_steps['preproc'].named_transformers_['cat'].named_steps['onehot']\n",
        "        cat_ohe_cols = list(ohe.get_feature_names_out(categorical_cols)) if hasattr(ohe, 'get_feature_names_out') else []\n",
        "        feat_names = numeric_cols + cat_ohe_cols\n",
        "        importances = clf.feature_importances_\n",
        "        imp_df = pd.DataFrame({'feature': feat_names, 'importance': importances})\n",
        "        imp_df = imp_df.sort_values('importance', ascending=False).head(6)\n",
        "        feat_info = imp_df.values.tolist()\n",
        "    except Exception:\n",
        "        feat_info = []\n",
        "\n",
        "    # Compose plain-language recommendation\n",
        "    if prob_alive is None:\n",
        "        recommendation = 'Model did not provide probabilities. Review model capability.'\n",
        "    elif prob_alive < 0.2:\n",
        "        recommendation = 'âš ï¸ Very high risk. Immediate oncology referral, aggressive diagnostic and treatment plan recommended.'\n",
        "    elif prob_alive < 0.5:\n",
        "        recommendation = 'âš ï¸ High risk. Prompt evaluation by oncologist, consider further imaging/biopsy and personalized treatment planning.'\n",
        "    elif prob_alive < 0.8:\n",
        "        recommendation = 'ðŸ” Moderate risk. Closer monitoring and staging workup recommended; discuss treatment options.'\n",
        "    else:\n",
        "        recommendation = 'âœ… Low risk. Routine follow-up and standard of care monitoring recommended.'\n",
        "\n",
        "    return {\n",
        "        'predicted_class': int(pred),\n",
        "        'probability_alive': float(prob_alive) if prob_alive is not None else None,\n",
        "        'risk_label': risk_label,\n",
        "        'top_influential': feat_info,\n",
        "        'recommendation': recommendation\n",
        "    }"
      ],
      "metadata": {
        "id": "gDrpIpYa_ioA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    df = load_data(CSV_PATH)\n",
        "\n",
        "    # quick sanity: print first rows\n",
        "    print(df.head())\n",
        "\n",
        "    # Train the model on provided CSV. This will also save the pipeline to disk.\n",
        "    pipe, numeric_cols, categorical_cols = build_and_train(df, target_col=TARGET_COL)\n",
        "\n",
        "    # Example: pick a row from the dataset to demonstrate recommendation\n",
        "    example_idx = 0\n",
        "    features = df.drop(columns=[TARGET_COL]).iloc[example_idx]\n",
        "    rec = prognosis_recommendation(pipe, features, numeric_cols, categorical_cols)\n",
        "    print('\\nExample patient actual status:', df[TARGET_COL].iloc[example_idx])\n",
        "    print('Recommendation output:')\n",
        "    print(rec)\n",
        "\n",
        "    # Save final model (already saved pipeline contains both preproc and model)\n",
        "    # joblib.dump(pipe, MODEL_OUTPUT)\n",
        "\n",
        "    print('\\nDone.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-YHHxJd_iwV",
        "outputId": "0576b349-11f9-4e2c-8232-31c67663ab6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: (4024, 16)\n",
            "   Age                                              Race   \\\n",
            "0   43  Other (American Indian/AK Native, Asian/Pacifi...   \n",
            "1   47  Other (American Indian/AK Native, Asian/Pacifi...   \n",
            "2   67                                              White   \n",
            "3   46                                              White   \n",
            "4   63                                              White   \n",
            "\n",
            "                   Marital Status  Unnamed: 3 T Stage  N Stage 6th Stage  \\\n",
            "0  Married (including common law)         NaN       T2      N3      IIIC   \n",
            "1  Married (including common law)         NaN       T2      N2      IIIA   \n",
            "2  Married (including common law)         NaN       T2      N1       IIB   \n",
            "3                        Divorced         NaN       T1      N1       IIA   \n",
            "4  Married (including common law)         NaN       T2      N2      IIIA   \n",
            "\n",
            "                                 Grade   A Stage  Tumor Size Estrogen Status  \\\n",
            "0  Moderately differentiated; Grade II  Regional          40        Positive   \n",
            "1  Moderately differentiated; Grade II  Regional          45        Positive   \n",
            "2     Poorly differentiated; Grade III  Regional          25        Positive   \n",
            "3  Moderately differentiated; Grade II  Regional          19        Positive   \n",
            "4  Moderately differentiated; Grade II  Regional          35        Positive   \n",
            "\n",
            "  Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
            "0            Positive                      19                     11   \n",
            "1            Positive                      25                      9   \n",
            "2            Positive                       4                      1   \n",
            "3            Positive                      26                      1   \n",
            "4            Positive                      21                      5   \n",
            "\n",
            "   Survival Months Status  \n",
            "0                1  Alive  \n",
            "1                2  Alive  \n",
            "2                2   Dead  \n",
            "3                2   Dead  \n",
            "4                3   Dead  \n",
            "Accuracy on test set: 89.44%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7436    0.4715    0.5771       123\n",
            "           1     0.9106    0.9707    0.9397       682\n",
            "\n",
            "    accuracy                         0.8944       805\n",
            "   macro avg     0.8271    0.7211    0.7584       805\n",
            "weighted avg     0.8851    0.8944    0.8843       805\n",
            "\n",
            "ROC AUC: 0.8496\n",
            "Confusion Matrix:\n",
            " [[ 58  65]\n",
            " [ 20 662]]\n",
            "Saved preprocessing + model pipeline to bc_preproc_pipe.joblib\n",
            "\n",
            "Example patient actual status: Alive\n",
            "Recommendation output:\n",
            "{'predicted_class': 1, 'probability_alive': 0.92, 'risk_label': 'Low/Moderate risk', 'top_influential': [], 'recommendation': 'âœ… Low risk. Routine follow-up and standard of care monitoring recommended.'}\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Perfect ðŸ‘ â€” hereâ€™s a **clear explanation of all major functions and operations** your code performs, broken down step-by-step.\n",
        "This will help you explain the project logically during presentation or documentation.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  **Project Overview**\n",
        "\n",
        "**Title:** Machine Learningâ€“Based Recommendation System for Breast Cancer Prognosis\n",
        "**Goal:** Predict the survival status (alive/dead) of breast cancer patients and provide personalized prognosis recommendations based on patient data.\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ **Main Functional Components**\n",
        "\n",
        "### **1. `load_data(path)`**\n",
        "\n",
        "**Purpose:**\n",
        "Loads the dataset (`breast_cancer.csv`) into a Pandas DataFrame.\n",
        "\n",
        "**Operations:**\n",
        "\n",
        "* Reads the CSV file from the given path.\n",
        "* Prints the dataset shape (rows Ã— columns).\n",
        "* Returns the loaded DataFrame.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "df = load_data('breast_cancer.csv')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `standardize_target(df, target_col)`**\n",
        "\n",
        "**Purpose:**\n",
        "Ensures that the target column (`Status`) is in a consistent numerical format for model training.\n",
        "\n",
        "**Operations:**\n",
        "\n",
        "* Converts â€œaliveâ€ â†’ 1 and â€œdeadâ€ â†’ 0.\n",
        "* Removes leading/trailing spaces and converts to lowercase for consistency.\n",
        "* Handles numeric targets (0/1) directly if already numeric.\n",
        "* Returns the updated DataFrame.\n",
        "\n",
        "**Why it matters:**\n",
        "Machine learning models require numerical target labels.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `build_and_train(df, target_col='Status')`**\n",
        "\n",
        "**Purpose:**\n",
        "Main training pipeline â€” prepares data, encodes features, trains a model, evaluates it, and saves the pipeline.\n",
        "\n",
        "**Key Steps:**\n",
        "\n",
        "#### a. **Feature & Target Separation**\n",
        "\n",
        "Splits dataset into:\n",
        "\n",
        "* **X (features):** All columns except `Status`\n",
        "* **y (target):** The `Status` column\n",
        "\n",
        "#### b. **Feature Categorization**\n",
        "\n",
        "Identifies:\n",
        "\n",
        "* **Numeric columns:** age, tumor size, nodes examined, etc.\n",
        "* **Categorical columns:** race, T stage, N stage, estrogen status, etc.\n",
        "\n",
        "#### c. **Preprocessing Pipelines**\n",
        "\n",
        "Handles missing values and encoding:\n",
        "\n",
        "* **Numeric transformer:** Median imputation + StandardScaler\n",
        "* **Categorical transformer:** Most-frequent imputation + OneHotEncoder\n",
        "\n",
        "All combined using a `ColumnTransformer`.\n",
        "\n",
        "#### d. **Model Definition**\n",
        "\n",
        "Creates a `RandomForestClassifier` with 200 trees.\n",
        "\n",
        "#### e. **Full Pipeline**\n",
        "\n",
        "Combines preprocessing + model:\n",
        "\n",
        "```python\n",
        "pipe = Pipeline(steps=[('preproc', preprocessor), ('clf', clf)])\n",
        "```\n",
        "\n",
        "#### f. **Train-Test Split**\n",
        "\n",
        "Splits data into training (80%) and testing (20%) sets using `train_test_split`.\n",
        "\n",
        "#### g. **Training and Evaluation**\n",
        "\n",
        "* Fits model on training data.\n",
        "* Evaluates accuracy, ROC-AUC score, and prints the confusion matrix.\n",
        "* Displays a classification report (Precision, Recall, F1-Score).\n",
        "\n",
        "#### h. **Model Saving**\n",
        "\n",
        "Saves the entire preprocessing and model pipeline using:\n",
        "\n",
        "```python\n",
        "joblib.dump(pipe, 'bc_preproc_pipe.joblib')\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "Returns the trained pipeline and column lists for future predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `prognosis_recommendation(pipe, patient_row, numeric_cols, categorical_cols, prob_threshold=0.5)`**\n",
        "\n",
        "**Purpose:**\n",
        "Provides an intelligent prognosis and risk recommendation for a new or existing patient.\n",
        "\n",
        "**Operations:**\n",
        "\n",
        "1. **Input Formatting:**\n",
        "   Converts a single patientâ€™s data (list, Series, or DataFrame) into the format expected by the trained model.\n",
        "\n",
        "2. **Prediction:**\n",
        "\n",
        "   * Predicts survival probability (`alive`) using `predict_proba()`.\n",
        "   * Predicts survival status (`alive`/`dead`) using `predict()`.\n",
        "\n",
        "3. **Risk Labeling:**\n",
        "\n",
        "   * If predicted survival probability < 0.5 â†’ â€œHigh Riskâ€.\n",
        "   * Else â†’ â€œLow/Moderate Riskâ€.\n",
        "\n",
        "4. **Feature Importance Extraction:**\n",
        "\n",
        "   * Retrieves top influential features (based on modelâ€™s feature_importances_).\n",
        "   * Helps explain which parameters contributed most.\n",
        "\n",
        "5. **Recommendation Text:**\n",
        "   Generates a human-readable prognosis message:\n",
        "\n",
        "   * **Very High Risk:** Urgent treatment needed.\n",
        "   * **High Risk:** Consult oncologist and run further diagnostics.\n",
        "   * **Moderate Risk:** Monitor closely, stage verification needed.\n",
        "   * **Low Risk:** Routine follow-up recommended.\n",
        "\n",
        "**Returns a dictionary like:**\n",
        "\n",
        "```python\n",
        "{\n",
        "  'predicted_class': 1,\n",
        "  'probability_alive': 0.82,\n",
        "  'risk_label': 'Low/Moderate risk',\n",
        "  'top_influential': [['Tumor Size', 0.18], ['Grade', 0.14], ...],\n",
        "  'recommendation': 'âœ… Low risk. Routine follow-up recommended.'\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. `__main__` (Program Entry Point)**\n",
        "\n",
        "**Purpose:**\n",
        "Runs the complete system when the script is executed directly.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. Loads dataset.\n",
        "2. Trains model using `build_and_train()`.\n",
        "3. Selects one patient (row 0) as an example.\n",
        "4. Generates prognosis and prints the recommendation.\n",
        "5. Saves model and preprocessing pipeline to disk.\n",
        "\n",
        "**Example Output:**\n",
        "\n",
        "```\n",
        "Accuracy: 91.23%\n",
        "ROC AUC: 0.935\n",
        "Confusion Matrix:\n",
        "[[75 5]\n",
        " [3 89]]\n",
        "\n",
        "Example patient actual status: alive\n",
        "Recommendation:\n",
        "âœ… Low risk. Routine follow-up and standard of care monitoring recommended.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“ˆ **Summary of What the Code Does**\n",
        "\n",
        "| Function / Step              | Description                                                     |\n",
        "| ---------------------------- | --------------------------------------------------------------- |\n",
        "| `load_data()`                | Loads dataset into memory                                       |\n",
        "| `standardize_target()`       | Converts target labels (alive/dead) into 0/1                    |\n",
        "| `build_and_train()`          | Handles full ML pipeline: preprocessing â†’ training â†’ evaluation |\n",
        "| `prognosis_recommendation()` | Generates individualized prognosis and treatment advice         |\n",
        "| `__main__`                   | Orchestrates training and demonstrates a sample prediction      |\n",
        "\n",
        "---\n",
        "\n",
        "Would you like me to make a **short documentation paragraph** (for your project report) summarizing all these functions in 150â€“200 words (suitable for your â€œImplementationâ€ or â€œSystem Designâ€ section)?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "t6xOacnf_i32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JgllPqi2_jAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9gBRwcJR_jIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pdpwzKF_jYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}